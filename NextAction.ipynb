{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NextAction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j3nguyen/user_item_embeddings/blob/master/NextAction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7lmWYxUscXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "# import gensim\n",
        "# import gensim.corpora as corpora\n",
        "# from gensim.utils import simple_preprocess\n",
        "# from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "# import spacy\n",
        "\n",
        "# NLTK for stopwords and stemming\n",
        "# from nltk.stem.porter import * \n",
        "# from nltk.stem.snowball import SnowballStemmer\n",
        "# from nltk.corpus import stopwords\n",
        "# stop_words = stopwords.words('english')\n",
        "\n",
        "# Plotting tools\n",
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJyyvljXsfw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "446980b1-84b4-45a5-fb85-acd0dcf6e9f0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru9frj6Xs7yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UlLuUz6s9lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, LSTM, Dense, Average, Dropout, Embedding, Activation, TimeDistributed, Concatenate, Flatten, Lambda\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfML1r4FxGRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"events.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdr9sjNNxO00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "574b48ac-6612-4ab8-e37a-76b4b54c16c1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>visitorid</th>\n",
              "      <th>event</th>\n",
              "      <th>itemid</th>\n",
              "      <th>transactionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1433221332117</td>\n",
              "      <td>257597</td>\n",
              "      <td>view</td>\n",
              "      <td>355908</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1433224214164</td>\n",
              "      <td>992329</td>\n",
              "      <td>view</td>\n",
              "      <td>248676</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1433221999827</td>\n",
              "      <td>111016</td>\n",
              "      <td>view</td>\n",
              "      <td>318965</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1433221955914</td>\n",
              "      <td>483717</td>\n",
              "      <td>view</td>\n",
              "      <td>253185</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1433221337106</td>\n",
              "      <td>951259</td>\n",
              "      <td>view</td>\n",
              "      <td>367447</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       timestamp  visitorid event  itemid  transactionid\n",
              "0  1433221332117     257597  view  355908            NaN\n",
              "1  1433224214164     992329  view  248676            NaN\n",
              "2  1433221999827     111016  view  318965            NaN\n",
              "3  1433221955914     483717  view  253185            NaN\n",
              "4  1433221337106     951259  view  367447            NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoC-P7sYxQYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reformat the data set\n",
        "visitor_ids = df.visitorid.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHMvV21cxg-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffa32c10-8d12-4101-fd03-e45f866ee268"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2756101, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdIig2DxoG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a36ad26b-1167-4583-bd35-29f4cf55960d"
      },
      "source": [
        "df.event.value_counts()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "view           2664312\n",
              "addtocart        69332\n",
              "transaction      22457\n",
              "Name: event, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQUbzn4-4Mq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "action_to_idx = {\"view\": 0, \"addtocart\": 1, \"transaction\": 2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEKxbog95qZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b908be3-e438-4bbe-d454-8f18dca6a3ea"
      },
      "source": [
        "# build the data set\n",
        "\n",
        "a = df[df.visitorid == visitor_ids[342]].sort_values(\"timestamp\").event.values\n",
        "a = list(map(lambda x: action_to_idx[x],a))\n",
        "a"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMaW7q4-6Btl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visitor_activity = {}\n",
        "\n",
        "for visitor in visitor_ids[:1000]:\n",
        "  # get user's actions in order of time\n",
        "  actions = df[df.visitorid == visitor].sort_values(\"timestamp\").event.values\n",
        "  \n",
        "  if len(actions) > 50:\n",
        "    actions = list(map(lambda x: action_to_idx[x],actions)) [:51] \n",
        "    visitor_activity[visitor] = actions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2az0tCkqfSTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 64\n",
        "num_actions = len(action_to_idx)\n",
        "input_length = 50\n",
        "num_users = len(visitor_activity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1gknWh-71CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the LSTM network\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(\n",
        "#     input_dim=num_actions,\n",
        "#     output_dim=hidden_size, #hidden layer dimension\n",
        "#     input_length=input_length,\n",
        "#     trainable=True\n",
        "#   )\n",
        "# )\n",
        "\n",
        "# model.add(LSTM(hidden_size, return_sequences=True))\n",
        "# model.add(Dropout(rate=0.5))\n",
        "# model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_actions, hidden_size, input_length=input_length))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "model.add(LSTM(hidden_size, return_sequences=False))\n",
        "\n",
        "model.add(Dropout(rate=0.5))\n",
        "# model.add(TimeDistributed(Dense(num_actions)))\n",
        "# model.add(Activation('softmax'))\n",
        "model.add(Dense(num_actions, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEUKZOnDe0rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create the LSTM  network using the functional API\n",
        "\n",
        "\n",
        "# sequence of actions\n",
        "A = Input(shape=(input_length,), name=\"actions\") #length of sequence, size of vocab\n",
        "\n",
        "# document ID\n",
        "U = Input(shape=(1,), name=\"users\")\n",
        "\n",
        "#create embedding for actions and for users\n",
        "a = Embedding(input_dim=num_actions, output_dim=hidden_size, input_length=input_length)(A) # shape 50,64\n",
        "u = Embedding(input_dim=num_users, output_dim=hidden_size, input_length=1)(U) # shape 1,64\n",
        "\n",
        "# combine embeddings\n",
        "x = Concatenate(axis=1)([u,a])\n",
        "\n",
        "# shared LSTM\n",
        "# x = Dense(hidden_size,activation='relu')(x)\n",
        "# # predictions = Flatten()(x\n",
        "\n",
        "split = Lambda(my_split(input_length))(x)\n",
        "averaged = Average()(split)\n",
        "squeezed = Lambda(squeeze(axis=1))(averaged)\n",
        "\n",
        "predictions = Dense(num_actions, activation='softmax')(squeezed)\n",
        "\n",
        "model = Model(inputs=[A, U], outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raV1uFssMs6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4XZ5wilM9cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dab46360-5243-4c40-bf18-f878989d4106"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "users (InputLayer)              (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "actions (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_36 (Embedding)        (None, 1, 64)        2432        users[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_35 (Embedding)        (None, 50, 64)       192         actions[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 51, 64)       0           embedding_36[0][0]               \n",
            "                                                                 embedding_35[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               [(None, 1, 64), (Non 0           concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_2 (Average)             (None, 1, 64)        0           lambda_4[0][0]                   \n",
            "                                                                 lambda_4[0][1]                   \n",
            "                                                                 lambda_4[0][2]                   \n",
            "                                                                 lambda_4[0][3]                   \n",
            "                                                                 lambda_4[0][4]                   \n",
            "                                                                 lambda_4[0][5]                   \n",
            "                                                                 lambda_4[0][6]                   \n",
            "                                                                 lambda_4[0][7]                   \n",
            "                                                                 lambda_4[0][8]                   \n",
            "                                                                 lambda_4[0][9]                   \n",
            "                                                                 lambda_4[0][10]                  \n",
            "                                                                 lambda_4[0][11]                  \n",
            "                                                                 lambda_4[0][12]                  \n",
            "                                                                 lambda_4[0][13]                  \n",
            "                                                                 lambda_4[0][14]                  \n",
            "                                                                 lambda_4[0][15]                  \n",
            "                                                                 lambda_4[0][16]                  \n",
            "                                                                 lambda_4[0][17]                  \n",
            "                                                                 lambda_4[0][18]                  \n",
            "                                                                 lambda_4[0][19]                  \n",
            "                                                                 lambda_4[0][20]                  \n",
            "                                                                 lambda_4[0][21]                  \n",
            "                                                                 lambda_4[0][22]                  \n",
            "                                                                 lambda_4[0][23]                  \n",
            "                                                                 lambda_4[0][24]                  \n",
            "                                                                 lambda_4[0][25]                  \n",
            "                                                                 lambda_4[0][26]                  \n",
            "                                                                 lambda_4[0][27]                  \n",
            "                                                                 lambda_4[0][28]                  \n",
            "                                                                 lambda_4[0][29]                  \n",
            "                                                                 lambda_4[0][30]                  \n",
            "                                                                 lambda_4[0][31]                  \n",
            "                                                                 lambda_4[0][32]                  \n",
            "                                                                 lambda_4[0][33]                  \n",
            "                                                                 lambda_4[0][34]                  \n",
            "                                                                 lambda_4[0][35]                  \n",
            "                                                                 lambda_4[0][36]                  \n",
            "                                                                 lambda_4[0][37]                  \n",
            "                                                                 lambda_4[0][38]                  \n",
            "                                                                 lambda_4[0][39]                  \n",
            "                                                                 lambda_4[0][40]                  \n",
            "                                                                 lambda_4[0][41]                  \n",
            "                                                                 lambda_4[0][42]                  \n",
            "                                                                 lambda_4[0][43]                  \n",
            "                                                                 lambda_4[0][44]                  \n",
            "                                                                 lambda_4[0][45]                  \n",
            "                                                                 lambda_4[0][46]                  \n",
            "                                                                 lambda_4[0][47]                  \n",
            "                                                                 lambda_4[0][48]                  \n",
            "                                                                 lambda_4[0][49]                  \n",
            "                                                                 lambda_4[0][50]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 64)           0           average_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 3)            195         lambda_5[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,819\n",
            "Trainable params: 2,819\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uyw081aNmZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab2b1953-8a29-4854-b364-efbe48cfefc1"
      },
      "source": [
        "max(list(map(lambda x: len(x),visitor_activity.values())))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJy3z1wFadTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RaGIAx7ll0jU",
        "colab": {}
      },
      "source": [
        "actions = visitor_activity.values()\n",
        "d_train = np.array(range(len(actions)))\n",
        "X_train = np.array(list(map(lambda x: x[:-1], actions))) \n",
        "y_train = to_categorical(np.array(list(map(lambda x: x[50], actions))), num_classes=3) # shift sequence on step forward\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b78uOWSdkGYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "048d7c26-8c6b-406c-ac7d-a48ad5c20b2c"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r0beNKrAlzxP",
        "colab": {}
      },
      "source": [
        "def my_split(window_size):\n",
        "    def _lambda(tensor):\n",
        "        import tensorflow as tf\n",
        "        return tf.split(tensor, window_size + 1, axis=1)\n",
        "    return _lambda\n",
        "\n",
        "\n",
        "def squeeze(axis=-1):\n",
        "    def _lambda(tensor):\n",
        "        import tensorflow as tf\n",
        "        return tf.squeeze(tensor, axis=axis)\n",
        "    return _lambda\n",
        "\n",
        "\n",
        "def stack(window_size):\n",
        "    def _lambda(tensor):\n",
        "        import tensorflow as tf\n",
        "        return tf.stack([tensor] * window_size, axis=1)\n",
        "    return _lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAJB-6K-XaTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdcf8857-8b05-457d-83c2-04d6fac14522"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(899, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "659x-AsLPw-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fc91bfe-f55a-4b4a-988a-e0e6808edce4"
      },
      "source": [
        "h = model.fit([X_train,d_train], y_train, epochs=50, batch_size=128, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0809 20:00:59.338821 140713835227008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0809 20:00:59.719427 140713835227008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 34 samples, validate on 4 samples\n",
            "Epoch 1/50\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 1.0792 - acc: 0.0294 - val_loss: 1.0060 - val_acc: 1.0000\n",
            "Epoch 2/50\n",
            "34/34 [==============================] - 0s 251us/step - loss: 1.0166 - acc: 0.9118 - val_loss: 0.9287 - val_acc: 1.0000\n",
            "Epoch 3/50\n",
            "34/34 [==============================] - 0s 260us/step - loss: 0.9484 - acc: 0.9118 - val_loss: 0.8490 - val_acc: 1.0000\n",
            "Epoch 4/50\n",
            "34/34 [==============================] - 0s 150us/step - loss: 0.8787 - acc: 0.9118 - val_loss: 0.7670 - val_acc: 1.0000\n",
            "Epoch 5/50\n",
            "34/34 [==============================] - 0s 156us/step - loss: 0.8078 - acc: 0.9118 - val_loss: 0.6829 - val_acc: 1.0000\n",
            "Epoch 6/50\n",
            "34/34 [==============================] - 0s 133us/step - loss: 0.7362 - acc: 0.9118 - val_loss: 0.5980 - val_acc: 1.0000\n",
            "Epoch 7/50\n",
            "34/34 [==============================] - 0s 145us/step - loss: 0.6652 - acc: 0.9118 - val_loss: 0.5142 - val_acc: 1.0000\n",
            "Epoch 8/50\n",
            "34/34 [==============================] - 0s 168us/step - loss: 0.5970 - acc: 0.9118 - val_loss: 0.4338 - val_acc: 1.0000\n",
            "Epoch 9/50\n",
            "34/34 [==============================] - 0s 156us/step - loss: 0.5339 - acc: 0.9118 - val_loss: 0.3592 - val_acc: 1.0000\n",
            "Epoch 10/50\n",
            "34/34 [==============================] - 0s 172us/step - loss: 0.4780 - acc: 0.9118 - val_loss: 0.2923 - val_acc: 1.0000\n",
            "Epoch 11/50\n",
            "34/34 [==============================] - 0s 191us/step - loss: 0.4309 - acc: 0.9118 - val_loss: 0.2345 - val_acc: 1.0000\n",
            "Epoch 12/50\n",
            "34/34 [==============================] - 0s 143us/step - loss: 0.3936 - acc: 0.9118 - val_loss: 0.1862 - val_acc: 1.0000\n",
            "Epoch 13/50\n",
            "34/34 [==============================] - 0s 143us/step - loss: 0.3660 - acc: 0.9118 - val_loss: 0.1473 - val_acc: 1.0000\n",
            "Epoch 14/50\n",
            "34/34 [==============================] - 0s 164us/step - loss: 0.3473 - acc: 0.9118 - val_loss: 0.1167 - val_acc: 1.0000\n",
            "Epoch 15/50\n",
            "34/34 [==============================] - 0s 152us/step - loss: 0.3359 - acc: 0.9118 - val_loss: 0.0933 - val_acc: 1.0000\n",
            "Epoch 16/50\n",
            "34/34 [==============================] - 0s 151us/step - loss: 0.3302 - acc: 0.9118 - val_loss: 0.0757 - val_acc: 1.0000\n",
            "Epoch 17/50\n",
            "34/34 [==============================] - 0s 158us/step - loss: 0.3284 - acc: 0.9118 - val_loss: 0.0626 - val_acc: 1.0000\n",
            "Epoch 18/50\n",
            "34/34 [==============================] - 0s 160us/step - loss: 0.3290 - acc: 0.9118 - val_loss: 0.0531 - val_acc: 1.0000\n",
            "Epoch 19/50\n",
            "34/34 [==============================] - 0s 141us/step - loss: 0.3306 - acc: 0.9118 - val_loss: 0.0463 - val_acc: 1.0000\n",
            "Epoch 20/50\n",
            "34/34 [==============================] - 0s 189us/step - loss: 0.3324 - acc: 0.9118 - val_loss: 0.0415 - val_acc: 1.0000\n",
            "Epoch 21/50\n",
            "34/34 [==============================] - 0s 151us/step - loss: 0.3337 - acc: 0.9118 - val_loss: 0.0382 - val_acc: 1.0000\n",
            "Epoch 22/50\n",
            "34/34 [==============================] - 0s 158us/step - loss: 0.3342 - acc: 0.9118 - val_loss: 0.0362 - val_acc: 1.0000\n",
            "Epoch 23/50\n",
            "34/34 [==============================] - 0s 140us/step - loss: 0.3335 - acc: 0.9118 - val_loss: 0.0352 - val_acc: 1.0000\n",
            "Epoch 24/50\n",
            "34/34 [==============================] - 0s 185us/step - loss: 0.3318 - acc: 0.9118 - val_loss: 0.0350 - val_acc: 1.0000\n",
            "Epoch 25/50\n",
            "34/34 [==============================] - 0s 164us/step - loss: 0.3289 - acc: 0.9118 - val_loss: 0.0355 - val_acc: 1.0000\n",
            "Epoch 26/50\n",
            "34/34 [==============================] - 0s 134us/step - loss: 0.3252 - acc: 0.9118 - val_loss: 0.0367 - val_acc: 1.0000\n",
            "Epoch 27/50\n",
            "34/34 [==============================] - 0s 129us/step - loss: 0.3207 - acc: 0.9118 - val_loss: 0.0386 - val_acc: 1.0000\n",
            "Epoch 28/50\n",
            "34/34 [==============================] - 0s 133us/step - loss: 0.3156 - acc: 0.9118 - val_loss: 0.0410 - val_acc: 1.0000\n",
            "Epoch 29/50\n",
            "34/34 [==============================] - 0s 144us/step - loss: 0.3101 - acc: 0.9118 - val_loss: 0.0441 - val_acc: 1.0000\n",
            "Epoch 30/50\n",
            "34/34 [==============================] - 0s 151us/step - loss: 0.3044 - acc: 0.9118 - val_loss: 0.0477 - val_acc: 1.0000\n",
            "Epoch 31/50\n",
            "34/34 [==============================] - 0s 127us/step - loss: 0.2987 - acc: 0.9118 - val_loss: 0.0519 - val_acc: 1.0000\n",
            "Epoch 32/50\n",
            "34/34 [==============================] - 0s 140us/step - loss: 0.2931 - acc: 0.9118 - val_loss: 0.0566 - val_acc: 1.0000\n",
            "Epoch 33/50\n",
            "34/34 [==============================] - 0s 149us/step - loss: 0.2878 - acc: 0.9118 - val_loss: 0.0617 - val_acc: 1.0000\n",
            "Epoch 34/50\n",
            "34/34 [==============================] - 0s 132us/step - loss: 0.2830 - acc: 0.9118 - val_loss: 0.0674 - val_acc: 1.0000\n",
            "Epoch 35/50\n",
            "34/34 [==============================] - 0s 151us/step - loss: 0.2786 - acc: 0.9118 - val_loss: 0.0733 - val_acc: 1.0000\n",
            "Epoch 36/50\n",
            "34/34 [==============================] - 0s 171us/step - loss: 0.2747 - acc: 0.9118 - val_loss: 0.0795 - val_acc: 1.0000\n",
            "Epoch 37/50\n",
            "34/34 [==============================] - 0s 196us/step - loss: 0.2714 - acc: 0.9118 - val_loss: 0.0858 - val_acc: 1.0000\n",
            "Epoch 38/50\n",
            "34/34 [==============================] - 0s 169us/step - loss: 0.2685 - acc: 0.9118 - val_loss: 0.0920 - val_acc: 1.0000\n",
            "Epoch 39/50\n",
            "34/34 [==============================] - 0s 253us/step - loss: 0.2661 - acc: 0.9118 - val_loss: 0.0981 - val_acc: 1.0000\n",
            "Epoch 40/50\n",
            "34/34 [==============================] - 0s 172us/step - loss: 0.2641 - acc: 0.9118 - val_loss: 0.1038 - val_acc: 1.0000\n",
            "Epoch 41/50\n",
            "34/34 [==============================] - 0s 109us/step - loss: 0.2623 - acc: 0.9118 - val_loss: 0.1091 - val_acc: 1.0000\n",
            "Epoch 42/50\n",
            "34/34 [==============================] - 0s 196us/step - loss: 0.2607 - acc: 0.9118 - val_loss: 0.1137 - val_acc: 1.0000\n",
            "Epoch 43/50\n",
            "34/34 [==============================] - 0s 201us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.1177 - val_acc: 1.0000\n",
            "Epoch 44/50\n",
            "34/34 [==============================] - 0s 150us/step - loss: 0.2578 - acc: 0.9118 - val_loss: 0.1210 - val_acc: 1.0000\n",
            "Epoch 45/50\n",
            "34/34 [==============================] - 0s 113us/step - loss: 0.2562 - acc: 0.9118 - val_loss: 0.1235 - val_acc: 1.0000\n",
            "Epoch 46/50\n",
            "34/34 [==============================] - 0s 183us/step - loss: 0.2546 - acc: 0.9118 - val_loss: 0.1253 - val_acc: 1.0000\n",
            "Epoch 47/50\n",
            "34/34 [==============================] - 0s 136us/step - loss: 0.2528 - acc: 0.9118 - val_loss: 0.1264 - val_acc: 1.0000\n",
            "Epoch 48/50\n",
            "34/34 [==============================] - 0s 132us/step - loss: 0.2509 - acc: 0.9118 - val_loss: 0.1269 - val_acc: 1.0000\n",
            "Epoch 49/50\n",
            "34/34 [==============================] - 0s 129us/step - loss: 0.2489 - acc: 0.9118 - val_loss: 0.1268 - val_acc: 1.0000\n",
            "Epoch 50/50\n",
            "34/34 [==============================] - 0s 177us/step - loss: 0.2468 - acc: 0.9118 - val_loss: 0.1263 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xhoqc1uXOZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_prob = model.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuImBzNoioQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.argmax(pred_prob,axis=1)\n",
        "# pred_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F70aDmLSkDpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = np.argmax(y_train,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR9MtTIhlOkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score, roc_auc_score, roc_curve\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzZWDH0ulqfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "1a6c0105-f4c1-429e-d7d6-5e3eed0e39d9"
      },
      "source": [
        "conf=confusion_matrix(y_true,y_pred)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(conf, classes=action_to_idx.keys(), normalize=False,\n",
        "                      title='Normalized confusion matrix')\n",
        "# plt.savefig(\"cm1.jpg\", dpi=900)\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[815   3   0]\n",
            " [ 30  27   0]\n",
            " [ 19   0   5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEYCAYAAAA+mm/EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnXMuA0+QzjmXwf8DJAz+CcxjsOcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFB0Af9KwgVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = model.get_layer(index = 0)\n",
        "# embeddings = embeddings.get_weights()[0]\n",
        "# embeddings = embeddings / np.linalg.norm(embeddings, axis = 1).reshape((-1, 1))\n",
        "# embeddings = np.nan_to_num(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Mw2H4Yw4vn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "47eae192-1020-4053-c842-c237e2426e9a"
      },
      "source": [
        "embeddings.get_weights()[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.08706358,  0.09271353,  0.08502078,  0.09019545, -0.08043931,\n",
              "        -0.09067073, -0.01227337,  0.01120501, -0.11055698,  0.13738512,\n",
              "         0.08713342, -0.04729249,  0.0355525 , -0.0277873 ,  0.07280742,\n",
              "        -0.07964912, -0.05531936,  0.05751584, -0.0772675 , -0.11352045,\n",
              "         0.10077238,  0.12277301,  0.1571238 ,  0.11177433, -0.14619397,\n",
              "         0.00510582, -0.11321653,  0.09460485, -0.08353873,  0.12845778,\n",
              "         0.08458994, -0.13261339, -0.09591156, -0.06414989, -0.07438275,\n",
              "         0.05879742, -0.15737331,  0.05979951,  0.08880579,  0.08406407,\n",
              "        -0.04344111,  0.02285824, -0.12328462,  0.03212866,  0.05556991,\n",
              "        -0.11058971, -0.14004196, -0.08245189,  0.05606992,  0.04877523,\n",
              "        -0.1343911 , -0.052642  , -0.09082484,  0.05925634, -0.05577582,\n",
              "        -0.01988778, -0.09439526, -0.07643218, -0.12931322, -0.1041666 ,\n",
              "        -0.10514895,  0.08759594, -0.08213259,  0.12270011],\n",
              "       [-0.06843866, -0.04315355, -0.18731564,  0.01164095,  0.07067909,\n",
              "        -0.00880987,  0.06909742, -0.33661452,  0.05892159, -0.14278956,\n",
              "         0.12483485,  0.38290843, -0.26474532, -0.1567478 ,  0.03922811,\n",
              "         0.1435182 ,  0.3794188 , -0.35133564, -0.02014823,  0.15760304,\n",
              "         0.02853918,  0.02568771, -0.21408275,  0.10029038,  0.18566428,\n",
              "         0.42188296,  0.08588075, -0.23504819,  0.15778789, -0.15420869,\n",
              "        -0.23972043,  0.10210633,  0.09507204,  0.1343032 ,  0.16033907,\n",
              "        -0.15583718,  0.2630091 , -0.00194176, -0.3237929 ,  0.15510264,\n",
              "         0.33034226, -0.30351365, -0.08749991,  0.14879787, -0.30998546,\n",
              "         0.08904405,  0.09533586,  0.10542915, -0.20224822,  0.20360449,\n",
              "         0.05653125, -0.3242472 ,  0.06209663, -0.27123994, -0.12073029,\n",
              "        -0.4073791 ,  0.07376501, -0.11472382,  0.06502764,  0.09632745,\n",
              "         0.05270666, -0.32057455,  0.00718609, -0.17180571],\n",
              "       [-0.26231408, -0.43109164, -0.24997087, -0.53017056,  0.37286854,\n",
              "         0.5505241 ,  0.34653765, -0.25078413,  0.04281489, -0.25658652,\n",
              "        -0.5507487 ,  0.39533943, -0.39399505, -0.07391591, -0.6001416 ,\n",
              "         0.52294606,  0.1965974 , -0.43657306,  0.53871465,  0.39426857,\n",
              "        -0.39300904, -0.4249116 , -0.04317591,  0.034051  ,  0.21149081,\n",
              "         0.31092596,  0.12857139, -0.4297746 ,  0.6035946 , -0.05152562,\n",
              "        -0.4126419 ,  0.13892654,  0.17653692,  0.18352683,  0.36499146,\n",
              "        -0.4831922 ,  0.14318515, -0.24183771, -0.09451333, -0.5855877 ,\n",
              "         0.4253019 , -0.29730016,  0.47573504, -0.5407103 , -0.35089806,\n",
              "         0.36380076,  0.3677104 ,  0.5858783 , -0.10362971,  0.01006293,\n",
              "         0.44781515,  0.79386103,  0.39498705, -0.29755116,  0.391921  ,\n",
              "        -0.17583553,  0.39900962,  0.64948237,  0.111219  ,  0.3839858 ,\n",
              "         0.30919248, -0.24221262, -0.09505526, -0.04530392]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqC3evCiw74i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USNlUWrxwBT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}